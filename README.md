This is the code repository for the image caption project.  
Model structure: CLIP+LSTM  
CLIP: for image feature and text feature extraction  
LSTM: for caption generation. The input feature is the combination of image feature and text feature.  
Metrics: BLEU-4, ROUGE, METEOR, SPICE and CIDEr.   
Dataset: Vizwiz. Dataset specially designed for assisting people with vision impairments to overcome their real daily visual challenges. Suitable for tasks including Visual Question Answering, Image Caption and so on.
